cv::Mat rotateImage(const cv::Mat& source, double angle) {cv::Point2f src_center(source.cols / 2.0F, source.rows / 2.0F);cv::Mat rot_mat = getRotationMatrix2D(src_center, angle, 1.0);cv::Mat dst;warpAffine(source, dst, rot_mat, source.size());return dst;}inline static double square(int a) {return a * a;}inline static void allouer(IplImage **img, CvSize size, int depth, intchannels) {if (*img != NULL) return;*img = cvCreateImage(size, depth, channels);if (*img == NULL) {fprintf(stderr, "Erreur");exit(-1);}}
int main(void) {// Créer un objet pour décoder flux vidéoCvCapture *input_video = cvCaptureFromFile("../FlowDetectionVideo/citesciences.mpg");if (input_video == NULL) {fprintf(stderr, "Erreur");return -1;}CvSize frame_size;frame_size.height =(int) cvGetCaptureProperty(input_video,CV_CAP_PROP_FRAME_HEIGHT);frame_size.width =(int) cvGetCaptureProperty(input_video,CV_CAP_PROP_FRAME_WIDTH);//Nombre de frames dans la vidéolong number_of_frames;
cvSetCaptureProperty(input_video, CV_CAP_PROP_POS_AVI_RATIO, 1.);number_of_frames = (int) cvGetCaptureProperty(input_video,CV_CAP_PROP_POS_FRAMES);cvSetCaptureProperty(input_video, CV_CAP_PROP_POS_FRAMES, 0.);cvNamedWindow("Optical Flow", CV_WINDOW_AUTOSIZE);long current_frame = 0;while (true) {static IplImage *frame = NULL, *frame1 = NULL, *frame1_1C = NULL,*frame2_1C = NULL, *eig_image = NULL, *temp_image = NULL, *pyramid1 =NULL, *pyramid2 = NULL;cvSetCaptureProperty(input_video, CV_CAP_PROP_POS_FRAMES,current_frame);frame = cvQueryFrame(input_video);if (frame == NULL) {fprintf(stderr, "Erreur");return -1;}allouer(&frame1_1C, frame_size, IPL_DEPTH_8U, 1);cvConvertImage(frame, frame1_1C, CV_CVTIMG_FLIP);allouer(&frame1, frame_size, IPL_DEPTH_8U, 3);cvConvertImage(frame, frame1, CV_CVTIMG_FLIP);
frame = cvQueryFrame(input_video);if (frame == NULL) {fprintf(stderr, "Erreur");return -1;}allouer(&frame2_1C, frame_size, IPL_DEPTH_8U, 1);cvConvertImage(frame, frame2_1C, CV_CVTIMG_FLIP);allouer(&eig_image, frame_size, IPL_DEPTH_32F, 1);allouer(&temp_image, frame_size, IPL_DEPTH_32F, 1);CvPoint2D32f frame1_features[400];int number_of_features;number_of_features = 400;cvGoodFeaturesToTrack(frame1_1C, eig_image, temp_image,frame1_features, &number_of_features, .01, .01, NULL);CvPoint2D32f frame2_features[400];CvSize optical_flow_window = cvSize(3, 3);
CvTermCriteria optical_flow_termination_criteria= cvTermCriteria(CV_TERMCRIT_ITER | CV_TERMCRIT_EPS, 20, .3);allouer(&pyramid1, frame_size, IPL_DEPTH_8U, 1);allouer(&pyramid2, frame_size, IPL_DEPTH_8U, 1);cvCalcOpticalFlowPyrLK(frame1_1C, frame2_1C, pyramid1, pyramid2,frame1_features, frame2_features, number_of_features,optical_flow_window, 5, optical_flow_found_feature, optical_flow_feature_error, optical_flow_termination_criteria, 0);for (int i = 0; i < number_of_features; i++) {if (optical_flow_found_feature[i] == 0) continue;int line_thickness;line_thickness = 1;CvScalar line_color;line_color = CV_RGB(0, 255, 0);CvPoint p, q;p.x = (int) frame1_features[i].x;p.y = (int) frame1_features[i].y;q.x = (int) frame2_features[i].x;q.y = (int) frame2_features[i].y;double angle;angle = atan2((double) p.y - q.y, (double) p.x - q.x);double hypotenuse;hypotenuse = sqrt(square(p.y - q.y) + square(p.x - q.x));
q.x = (int) (p.x - 3 * hypotenuse * cos(angle));q.y = (int) (p.y - 3 * hypotenuse * sin(angle));cvLine(frame1, p, q, line_color, line_thickness, CV_AA, 0);p.x = (int) (q.x + 9 * cos(angle + pi / 4));p.y = (int) (q.y + 9 * sin(angle + pi / 4));cvLine(frame1, p, q, line_color, line_thickness, CV_AA, 0);p.x = (int) (q.x + 9 * cos(angle - pi / 4));p.y = (int) (q.y + 9 * sin(angle - pi / 4));cvLine(frame1, p, q, line_color, line_thickness, CV_AA, 0);}cvShowImage("Optical Flow", frame1);int key_pressed;key_pressed = cvWaitKey(0);
if (key_pressed == 'b' || key_pressed == 'B') current_frame--;else current_frame++;if (current_frame < 0) current_frame = 0;if (current_frame >= number_of_frames - 1) current_frame =number_of_frames - 2;}}